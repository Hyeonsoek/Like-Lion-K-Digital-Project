{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 타이타닉 생존자 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zKbTYjWpx03n"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> <span style='font-size:20pt;'>Preparing dataset </span>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('titanic.csv')\n",
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data info\n",
    "\n",
    "- **PassengerId** : Unique ID of passenger\n",
    "- **Survived** : 0 = No, 1 = Yes\n",
    "- **pclass** : Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)\n",
    "- **sibsp** : # of siblings & spouses aboard the Titanic\n",
    "- **parch** : # of parents / children aboard the Titanic\n",
    "- **ticket** : Ticket number\n",
    "- **cabin** : Cabin number\n",
    "- **embarked** : Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13775,
     "status": "ok",
     "timestamp": 1546723556658,
     "user": {
      "displayName": "Daeyeon Jo",
      "photoUrl": "https://lh4.googleusercontent.com/-9t4wvx9MYls/AAAAAAAAAAI/AAAAAAAAAC0/SPqWlKvQQMk/s64/photo.jpg",
      "userId": "05542487530960824006"
     },
     "user_tz": -540
    },
    "id": "EqR4honW16jn",
    "outputId": "35909889-315d-4a5f-815d-ce1535201ae0"
   },
   "outputs": [],
   "source": [
    "y_data = data_df[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_df['Survived']\n",
    "x_data = data_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> <span style='font-size:20pt;'> Feature engineering & Feature selection </span>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# LabelEncoder로 문자열을 간단한 숫자로 보기쉽게 바꿈\n",
    "le = LabelEncoder()\n",
    "x_data['Gender'] = le.fit_transform(x_data['Sex'])\n",
    "x_data['Embarked'] = le.fit_transform(x_data['Embarked'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_data['PassengerId']\n",
    "del x_data['Name']\n",
    "del x_data['Ticket']\n",
    "del x_data['Sex']\n",
    "del x_data['Cabin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3은 빈 열인데, 이게 3개밖에 안되서 삭제했음\n",
    "drop_Embarked_3 = x_data[x_data['Embarked'] == 3].index\n",
    "y_data = y_data.drop(drop_Embarked_3)\n",
    "x_data = x_data.drop(drop_Embarked_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age의 빈부분을 중앙값으로 대체\n",
    "x_data['Age'] = x_data['Age'].fillna(x_data['Age'].median(skipna=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fare열의 상위 15% 삭제\n",
    "x_data = x_data[ x_data['Fare'] <= x_data['Fare'].quantile(.85) ]\n",
    "y_data = y_data.loc[x_data.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> <span style='font-size:20pt;'> Train - Test split and Scaling, One-Hot Encoding </span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pclass, Embarked, SibSp, Parch열을 OneHotEncoding함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 스플릿\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(x_data, y_data, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# OneHotEncoder 선언\n",
    "# sparse 옵션 = OneHotEncode는 기본적으로 sparse matrix를 주기때문에\n",
    "# 이 옵션을 꺼야 원본 행렬 데이터를 가져올수있음\n",
    "# sparse matrix = 희소행렬, 1과 0만 있는 데이터에서 행렬 위치만을 저장하는 방식\n",
    "one_hot = OneHotEncoder(sparse=False, dtype=int)\n",
    "\n",
    "features = ['Pclass','Embarked','SibSp','Parch']\n",
    "one_hot.fit(X_train[features])\n",
    "\n",
    "X_train_onehot = pd.DataFrame(one_hot.transform(X_train[features]))\n",
    "X_test_onehot = pd.DataFrame(one_hot.transform(X_test[features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = []\n",
    "for name, category in zip(features, one_hot.categories_):\n",
    "    columns_name += [name + '_' + str(x) for x in range(len(category))]\n",
    "X_train_onehot.columns = columns_name\n",
    "X_test_onehot.columns = columns_name\n",
    "\n",
    "X_train_onehot = pd.concat([X_train_onehot, \n",
    "                X_train[['Age','Fare','Gender']].reset_index(drop=True)], axis=1)\n",
    "X_test_onehot = pd.concat([X_test_onehot,\n",
    "                X_test[['Age','Fare','Gender']].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> <span style='font-size:20pt;'>Model Training</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* XGBoost, GridSearchCv 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 45 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8149779735682819\n",
      "0.7887755102040815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       147\n",
      "           1       0.76      0.70      0.73        80\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       227\n",
      "   macro avg       0.80      0.79      0.79       227\n",
      "weighted avg       0.81      0.81      0.81       227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 검증에 필요한 KFold\n",
    "cv = KFold(n_splits=4)\n",
    "\n",
    "# Grid Search 기법에 필요한 파라미터 dict\n",
    "parameter = {\n",
    "        'n_estimators' : [ 1000 ],\n",
    "        'max_depth' : [3,6,9],\n",
    "        'min_child_weight' : [1,3,5],\n",
    "        'gamma' : [ x/10.0 for x in range(0,5) ],\n",
    "        'subsample' : [0.7],\n",
    "        'colsample_bytree' : [0.8],\n",
    "        'learning_rate' : [0.1],\n",
    "        'n_jobs' : [4]\n",
    "}\n",
    "\n",
    "# 학습 및 예측 결과\n",
    "grid_xgb_clf = GridSearchCV(\n",
    "                    XGBClassifier(),\n",
    "                    param_grid=parameter,\n",
    "                    scoring='accuracy',\n",
    "                    cv=cv,\n",
    "                    verbose=1\n",
    "                )\n",
    "\n",
    "grid_xgb_clf.fit(X_train_onehot, y_train)\n",
    "grid_xgb_pred = grid_xgb_clf.predict(X_test_onehot)\n",
    "\n",
    "print(accuracy_score(y_test, grid_xgb_pred))\n",
    "print(roc_auc_score(y_test, grid_xgb_pred))\n",
    "print(classification_report(y_test, grid_xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.8,\n",
       "  'gamma': 0.2,\n",
       "  'learning_rate': 0.1,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 5,\n",
       "  'n_estimators': 1000,\n",
       "  'n_jobs': 4,\n",
       "  'subsample': 0.7},\n",
       " 0.8162878787878788)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_xgb_clf.best_params_, grid_xgb_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'gamma': 0.0, 'learn...</td>\n",
       "      <td>0.799242</td>\n",
       "      <td>0.810606</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'gamma': 0.0, 'learn...</td>\n",
       "      <td>0.810606</td>\n",
       "      <td>0.810606</td>\n",
       "      <td>0.780303</td>\n",
       "      <td>0.840909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'gamma': 0.0, 'learn...</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'gamma': 0.0, 'learn...</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.840909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'gamma': 0.0, 'learn...</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score                                             params  \\\n",
       "0               35  {'colsample_bytree': 0.8, 'gamma': 0.0, 'learn...   \n",
       "1               11  {'colsample_bytree': 0.8, 'gamma': 0.0, 'learn...   \n",
       "2               17  {'colsample_bytree': 0.8, 'gamma': 0.0, 'learn...   \n",
       "3               38  {'colsample_bytree': 0.8, 'gamma': 0.0, 'learn...   \n",
       "4               38  {'colsample_bytree': 0.8, 'gamma': 0.0, 'learn...   \n",
       "\n",
       "   mean_test_score  split0_test_score  split1_test_score  split2_test_score  \n",
       "0         0.799242           0.810606           0.772727           0.833333  \n",
       "1         0.810606           0.810606           0.780303           0.840909  \n",
       "2         0.806818           0.772727           0.757576           0.848485  \n",
       "3         0.795455           0.795455           0.757576           0.840909  \n",
       "4         0.795455           0.803030           0.757576           0.833333  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_xgb_clf.cv_results_)[['rank_test_score','params','mean_test_score','split0_test_score',\n",
    "           'split1_test_score','split2_test_score']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25070066b70>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_importance(grid_xgb_clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Voting Ensanble 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridSeach 함수\n",
    "# models = 모델들이 담겨있는 list\n",
    "# parameters = 모델들의 파라미터 정보(dict)가 담겨있는 list\n",
    "# X_train, y_train, X_test, y_test 학습시 필요\n",
    "def model_gridSearch(models, parameters, X_train, X_test, y_train, y_test):\n",
    "    results = []\n",
    "    for model, parameter in zip(models, parameters):\n",
    "        cv = KFold(n_splits=4)\n",
    "        grid_model = GridSearchCV(\n",
    "                        model, param_grid=parameter,\n",
    "                        verbose=3, scoring='accuracy', cv=cv\n",
    "                    )\n",
    "        \n",
    "        grid_model.fit(X_train_ss, y_train)\n",
    "        grid_model_pred = grid_model.predict(X_test_ss)\n",
    "        \n",
    "        results.append(grid_model.best_estimator_)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 회귀 분류 모델 다 가져오기\n",
    "lr_clf = LogisticRegression()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "xgb_clf = XGBClassifier()\n",
    "\n",
    "models = [lr_clf, dt_clf, knn_clf, xgb_clf]\n",
    "\n",
    "# 각각의 모델에 맞는 하이퍼 파라미터 셋 선언 및 저장\n",
    "dt_param = {\n",
    "    'max_depth' : [4,5,6],\n",
    "    'max_features' : [3, 6, 9, 15]\n",
    "}\n",
    "\n",
    "lr_param = {\n",
    "    'penalty' : ['l2'],\n",
    "    'C' : [x * 0.1 for x in range(5,11,2)],\n",
    "    'solver' : ['newton-cg', 'lbfgs','liblinear','sag','saga'],\n",
    "    'max_iter' : [50,100,150]\n",
    "}\n",
    "\n",
    "knn_param = {\n",
    "    'n_neighbors' : [3,5,7],\n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "xgb_param = {\n",
    "        'n_estimators' : [ 1000 ],\n",
    "        'max_depth' : [3,6,9],\n",
    "        'min_child_weight' : [1,3,5],\n",
    "        'gamma' : [ x/10.0 for x in range(0,5) ],\n",
    "        'subsample' : [0.7],\n",
    "        'colsample_bytree' : [0.8],\n",
    "        'learning_rate' : [0.1],\n",
    "        'n_jobs' : [4]\n",
    "}\n",
    "\n",
    "params = [lr_param, dt_param, knn_param, xgb_param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 45 candidates, totalling 180 fits\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=newton-cg ................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=newton-cg, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=newton-cg ................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=newton-cg, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=newton-cg ................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=newton-cg, score=0.7196969696969697, total=   0.0s\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=newton-cg ................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=newton-cg, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=lbfgs ....................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=lbfgs, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=lbfgs ....................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=lbfgs, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=lbfgs ....................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=lbfgs, score=0.7196969696969697, total=   0.0s\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=lbfgs ....................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=lbfgs, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=liblinear ................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=liblinear, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=liblinear ................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=liblinear, score=0.6666666666666666, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=liblinear ................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=liblinear, score=0.7196969696969697, total=   0.0s\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=liblinear ................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=liblinear, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=sag ......................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=sag, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=sag ......................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=sag, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=sag ......................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=sag, score=0.7196969696969697, total=   0.0s\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=sag ......................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=sag, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=saga .....................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=saga, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=saga .....................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=saga, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=saga .....................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=saga, score=0.7196969696969697, total=   0.0s\n",
      "[CV] C=0.5, max_iter=50, penalty=l2, solver=saga .....................\n",
      "[CV]  C=0.5, max_iter=50, penalty=l2, solver=saga, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=newton-cg ...............\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=newton-cg, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=newton-cg ...............\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=newton-cg, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=newton-cg ...............\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=newton-cg, score=0.7196969696969697, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=newton-cg ...............\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=newton-cg, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=lbfgs ...................\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=lbfgs, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=lbfgs ...................\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=lbfgs, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=lbfgs ...................\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=lbfgs, score=0.7196969696969697, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=lbfgs ...................\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=lbfgs, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=liblinear ...............\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=liblinear, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=liblinear ...............\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=liblinear, score=0.6666666666666666, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=liblinear ...............\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=liblinear, score=0.7196969696969697, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=liblinear ...............\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=liblinear, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=sag .....................\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=sag, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=sag .....................\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=sag, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=sag .....................\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=sag, score=0.7196969696969697, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=sag .....................\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=sag, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=saga ....................\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=saga, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=saga ....................\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=saga, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=saga ....................\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=saga, score=0.7196969696969697, total=   0.0s\n",
      "[CV] C=0.5, max_iter=100, penalty=l2, solver=saga ....................\n",
      "[CV]  C=0.5, max_iter=100, penalty=l2, solver=saga, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=newton-cg ...............\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=newton-cg, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=newton-cg ...............\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=newton-cg, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=newton-cg ...............\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=newton-cg, score=0.7196969696969697, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=newton-cg ...............\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=newton-cg, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=lbfgs ...................\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=lbfgs, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=lbfgs ...................\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=lbfgs, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=lbfgs ...................\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=lbfgs, score=0.7196969696969697, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=lbfgs ...................\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=lbfgs, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=liblinear ...............\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=liblinear, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=liblinear ...............\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=liblinear, score=0.6666666666666666, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=liblinear ...............\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=liblinear, score=0.7196969696969697, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=liblinear ...............\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=liblinear, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=sag .....................\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=sag, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=sag .....................\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=sag, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=sag .....................\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=sag, score=0.7196969696969697, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=sag .....................\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=sag, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=saga ....................\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=saga, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=saga ....................\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=saga, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=saga ....................\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=saga, score=0.7196969696969697, total=   0.0s\n",
      "[CV] C=0.5, max_iter=150, penalty=l2, solver=saga ....................\n",
      "[CV]  C=0.5, max_iter=150, penalty=l2, solver=saga, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=newton-cg .\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=newton-cg, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=newton-cg .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=newton-cg, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=newton-cg .\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=newton-cg, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=newton-cg .\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=newton-cg, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=lbfgs .....\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=lbfgs, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=lbfgs .....\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=lbfgs, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=lbfgs .....\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=lbfgs, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=lbfgs .....\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=lbfgs, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=liblinear .\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=liblinear, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=liblinear .\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=liblinear, score=0.6515151515151515, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=liblinear .\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=liblinear, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=liblinear .\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=liblinear, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=sag .......\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=sag, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=sag .......\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=sag, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=sag .......\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=sag, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=sag .......\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=sag, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=saga ......\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=saga, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=saga ......\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=saga, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=saga ......\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=saga, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=50, penalty=l2, solver=saga ......\n",
      "[CV]  C=0.7000000000000001, max_iter=50, penalty=l2, solver=saga, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=newton-cg \n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=newton-cg, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=newton-cg \n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=newton-cg, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=newton-cg \n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=newton-cg, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=newton-cg \n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=newton-cg, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=lbfgs ....\n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=lbfgs, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=lbfgs ....\n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=lbfgs, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=lbfgs ....\n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=lbfgs, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=lbfgs ....\n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=lbfgs, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=liblinear \n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=liblinear, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=liblinear \n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=liblinear, score=0.6515151515151515, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=liblinear \n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=liblinear, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=liblinear \n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=liblinear, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=sag ......\n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=sag, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=sag ......\n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=sag, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=sag ......\n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=sag, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=sag ......\n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=sag, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=saga .....\n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=saga, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=saga .....\n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=saga, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=saga .....\n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=saga, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=100, penalty=l2, solver=saga .....\n",
      "[CV]  C=0.7000000000000001, max_iter=100, penalty=l2, solver=saga, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=newton-cg \n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=newton-cg, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=newton-cg \n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=newton-cg, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=newton-cg \n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=newton-cg, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=newton-cg \n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=newton-cg, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=lbfgs ....\n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=lbfgs, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=lbfgs ....\n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=lbfgs, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=lbfgs ....\n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=lbfgs, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=lbfgs ....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=lbfgs, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=liblinear \n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=liblinear, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=liblinear \n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=liblinear, score=0.6515151515151515, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=liblinear \n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=liblinear, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=liblinear \n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=liblinear, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=sag ......\n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=sag, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=sag ......\n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=sag, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=sag ......\n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=sag, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=sag ......\n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=sag, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=saga .....\n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=saga, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=saga .....\n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=saga, score=0.6439393939393939, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=saga .....\n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=saga, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.7000000000000001, max_iter=150, penalty=l2, solver=saga .....\n",
      "[CV]  C=0.7000000000000001, max_iter=150, penalty=l2, solver=saga, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=newton-cg ................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=newton-cg, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=newton-cg ................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=newton-cg, score=0.6515151515151515, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=newton-cg ................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=newton-cg, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=newton-cg ................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=newton-cg, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=lbfgs ....................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=lbfgs, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=lbfgs ....................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=lbfgs, score=0.6515151515151515, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=lbfgs ....................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=lbfgs, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=lbfgs ....................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=lbfgs, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=liblinear ................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=liblinear, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=liblinear ................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=liblinear, score=0.6515151515151515, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=liblinear ................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=liblinear, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=liblinear ................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=liblinear, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=sag ......................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=sag, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=sag ......................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=sag, score=0.6515151515151515, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=sag ......................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=sag, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=sag ......................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=sag, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=saga .....................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=saga, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=saga .....................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=saga, score=0.6515151515151515, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=saga .....................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=saga, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=50, penalty=l2, solver=saga .....................\n",
      "[CV]  C=0.9, max_iter=50, penalty=l2, solver=saga, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=newton-cg ...............\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=newton-cg, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=newton-cg ...............\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=newton-cg, score=0.6515151515151515, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=newton-cg ...............\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=newton-cg, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=newton-cg ...............\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=newton-cg, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=lbfgs ...................\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=lbfgs, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=lbfgs ...................\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=lbfgs, score=0.6515151515151515, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=lbfgs ...................\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=lbfgs, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=lbfgs ...................\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=lbfgs, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=liblinear ...............\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=liblinear, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=liblinear ...............\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=liblinear, score=0.6515151515151515, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=liblinear ...............\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=liblinear, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=liblinear ...............\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=liblinear, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=sag .....................\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=sag, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=sag .....................\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=sag, score=0.6515151515151515, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=sag .....................\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=sag, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=sag .....................\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=sag, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=saga ....................\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=saga, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=saga ....................\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=saga, score=0.6515151515151515, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=saga ....................\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=saga, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=100, penalty=l2, solver=saga ....................\n",
      "[CV]  C=0.9, max_iter=100, penalty=l2, solver=saga, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=newton-cg ...............\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=newton-cg, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=newton-cg ...............\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=newton-cg, score=0.6515151515151515, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=newton-cg ...............\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=newton-cg, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=newton-cg ...............\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=newton-cg, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=lbfgs ...................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=lbfgs, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=lbfgs ...................\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=lbfgs, score=0.6515151515151515, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=lbfgs ...................\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=lbfgs, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=lbfgs ...................\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=lbfgs, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=liblinear ...............\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=liblinear, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=liblinear ...............\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=liblinear, score=0.6515151515151515, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=liblinear ...............\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=liblinear, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=liblinear ...............\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=liblinear, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=sag .....................\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=sag, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=sag .....................\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=sag, score=0.6515151515151515, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=sag .....................\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=sag, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=sag .....................\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=sag, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=saga ....................\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=saga, score=0.7424242424242424, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=saga ....................\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=saga, score=0.6515151515151515, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=saga ....................\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=saga, score=0.7348484848484849, total=   0.0s\n",
      "[CV] C=0.9, max_iter=150, penalty=l2, solver=saga ....................\n",
      "[CV]  C=0.9, max_iter=150, penalty=l2, solver=saga, score=0.7348484848484849, total=   0.0s\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "[CV] max_depth=4, max_features=3 .....................................\n",
      "[CV]  max_depth=4, max_features=3, score=0.7348484848484849, total=   0.0s\n",
      "[CV] max_depth=4, max_features=3 .....................................\n",
      "[CV]  max_depth=4, max_features=3, score=0.6818181818181818, total=   0.0s\n",
      "[CV] max_depth=4, max_features=3 .....................................\n",
      "[CV]  max_depth=4, max_features=3, score=0.7272727272727273, total=   0.0s\n",
      "[CV] max_depth=4, max_features=3 .....................................\n",
      "[CV]  max_depth=4, max_features=3, score=0.7348484848484849, total=   0.0s\n",
      "[CV] max_depth=4, max_features=6 .....................................\n",
      "[CV]  max_depth=4, max_features=6, score=0.7196969696969697, total=   0.0s\n",
      "[CV] max_depth=4, max_features=6 .....................................\n",
      "[CV]  max_depth=4, max_features=6, score=0.6136363636363636, total=   0.0s\n",
      "[CV] max_depth=4, max_features=6 .....................................\n",
      "[CV]  max_depth=4, max_features=6, score=0.6590909090909091, total=   0.0s\n",
      "[CV] max_depth=4, max_features=6 .....................................\n",
      "[CV]  max_depth=4, max_features=6, score=0.7196969696969697, total=   0.0s\n",
      "[CV] max_depth=4, max_features=9 .....................................\n",
      "[CV]  max_depth=4, max_features=9, score=0.7424242424242424, total=   0.0s\n",
      "[CV] max_depth=4, max_features=9 .....................................\n",
      "[CV]  max_depth=4, max_features=9, score=0.6590909090909091, total=   0.0s\n",
      "[CV] max_depth=4, max_features=9 .....................................\n",
      "[CV] .......... max_depth=4, max_features=9, score=0.75, total=   0.0s\n",
      "[CV] max_depth=4, max_features=9 .....................................\n",
      "[CV]  max_depth=4, max_features=9, score=0.7121212121212122, total=   0.0s\n",
      "[CV] max_depth=4, max_features=15 ....................................\n",
      "[CV]  max_depth=4, max_features=15, score=0.7348484848484849, total=   0.0s\n",
      "[CV] max_depth=4, max_features=15 ....................................\n",
      "[CV]  max_depth=4, max_features=15, score=0.6439393939393939, total=   0.0s\n",
      "[CV] max_depth=4, max_features=15 ....................................\n",
      "[CV]  max_depth=4, max_features=15, score=0.7424242424242424, total=   0.0s\n",
      "[CV] max_depth=4, max_features=15 ....................................\n",
      "[CV]  max_depth=4, max_features=15, score=0.7196969696969697, total=   0.0s\n",
      "[CV] max_depth=5, max_features=3 .....................................\n",
      "[CV]  max_depth=5, max_features=3, score=0.7196969696969697, total=   0.0s\n",
      "[CV] max_depth=5, max_features=3 .....................................\n",
      "[CV]  max_depth=5, max_features=3, score=0.6742424242424242, total=   0.0s\n",
      "[CV] max_depth=5, max_features=3 .....................................\n",
      "[CV]  max_depth=5, max_features=3, score=0.7424242424242424, total=   0.0s\n",
      "[CV] max_depth=5, max_features=3 .....................................\n",
      "[CV]  max_depth=5, max_features=3, score=0.7348484848484849, total=   0.0s\n",
      "[CV] max_depth=5, max_features=6 .....................................\n",
      "[CV]  max_depth=5, max_features=6, score=0.6742424242424242, total=   0.0s\n",
      "[CV] max_depth=5, max_features=6 .....................................\n",
      "[CV]  max_depth=5, max_features=6, score=0.6818181818181818, total=   0.0s\n",
      "[CV] max_depth=5, max_features=6 .....................................\n",
      "[CV]  max_depth=5, max_features=6, score=0.7196969696969697, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] max_depth=5, max_features=6 .....................................\n",
      "[CV]  max_depth=5, max_features=6, score=0.7272727272727273, total=   0.0s\n",
      "[CV] max_depth=5, max_features=9 .....................................\n",
      "[CV]  max_depth=5, max_features=9, score=0.7196969696969697, total=   0.0s\n",
      "[CV] max_depth=5, max_features=9 .....................................\n",
      "[CV]  max_depth=5, max_features=9, score=0.6439393939393939, total=   0.0s\n",
      "[CV] max_depth=5, max_features=9 .....................................\n",
      "[CV]  max_depth=5, max_features=9, score=0.7424242424242424, total=   0.0s\n",
      "[CV] max_depth=5, max_features=9 .....................................\n",
      "[CV]  max_depth=5, max_features=9, score=0.7272727272727273, total=   0.0s\n",
      "[CV] max_depth=5, max_features=15 ....................................\n",
      "[CV]  max_depth=5, max_features=15, score=0.7121212121212122, total=   0.0s\n",
      "[CV] max_depth=5, max_features=15 ....................................\n",
      "[CV]  max_depth=5, max_features=15, score=0.6363636363636364, total=   0.0s\n",
      "[CV] max_depth=5, max_features=15 ....................................\n",
      "[CV]  max_depth=5, max_features=15, score=0.6666666666666666, total=   0.0s\n",
      "[CV] max_depth=5, max_features=15 ....................................\n",
      "[CV]  max_depth=5, max_features=15, score=0.7272727272727273, total=   0.0s\n",
      "[CV] max_depth=6, max_features=3 .....................................\n",
      "[CV]  max_depth=6, max_features=3, score=0.7196969696969697, total=   0.0s\n",
      "[CV] max_depth=6, max_features=3 .....................................\n",
      "[CV]  max_depth=6, max_features=3, score=0.6212121212121212, total=   0.0s\n",
      "[CV] max_depth=6, max_features=3 .....................................\n",
      "[CV]  max_depth=6, max_features=3, score=0.7424242424242424, total=   0.0s\n",
      "[CV] max_depth=6, max_features=3 .....................................\n",
      "[CV]  max_depth=6, max_features=3, score=0.7272727272727273, total=   0.0s\n",
      "[CV] max_depth=6, max_features=6 .....................................\n",
      "[CV]  max_depth=6, max_features=6, score=0.7121212121212122, total=   0.0s\n",
      "[CV] max_depth=6, max_features=6 .....................................\n",
      "[CV]  max_depth=6, max_features=6, score=0.6590909090909091, total=   0.0s\n",
      "[CV] max_depth=6, max_features=6 .....................................\n",
      "[CV]  max_depth=6, max_features=6, score=0.696969696969697, total=   0.0s\n",
      "[CV] max_depth=6, max_features=6 .....................................\n",
      "[CV]  max_depth=6, max_features=6, score=0.7272727272727273, total=   0.0s\n",
      "[CV] max_depth=6, max_features=9 .....................................\n",
      "[CV]  max_depth=6, max_features=9, score=0.7121212121212122, total=   0.0s\n",
      "[CV] max_depth=6, max_features=9 .....................................\n",
      "[CV]  max_depth=6, max_features=9, score=0.6742424242424242, total=   0.0s\n",
      "[CV] max_depth=6, max_features=9 .....................................\n",
      "[CV]  max_depth=6, max_features=9, score=0.7121212121212122, total=   0.0s\n",
      "[CV] max_depth=6, max_features=9 .....................................\n",
      "[CV]  max_depth=6, max_features=9, score=0.7272727272727273, total=   0.0s\n",
      "[CV] max_depth=6, max_features=15 ....................................\n",
      "[CV]  max_depth=6, max_features=15, score=0.696969696969697, total=   0.0s\n",
      "[CV] max_depth=6, max_features=15 ....................................\n",
      "[CV]  max_depth=6, max_features=15, score=0.6363636363636364, total=   0.0s\n",
      "[CV] max_depth=6, max_features=15 ....................................\n",
      "[CV]  max_depth=6, max_features=15, score=0.7424242424242424, total=   0.0s\n",
      "[CV] max_depth=6, max_features=15 ....................................\n",
      "[CV]  max_depth=6, max_features=15, score=0.7272727272727273, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "[CV] algorithm=auto, n_neighbors=3, weights=uniform ..................\n",
      "[CV]  algorithm=auto, n_neighbors=3, weights=uniform, score=0.6136363636363636, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=3, weights=uniform ..................\n",
      "[CV]  algorithm=auto, n_neighbors=3, weights=uniform, score=0.6515151515151515, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=3, weights=uniform ..................\n",
      "[CV]  algorithm=auto, n_neighbors=3, weights=uniform, score=0.7045454545454546, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=3, weights=uniform ..................\n",
      "[CV]  algorithm=auto, n_neighbors=3, weights=uniform, score=0.7121212121212122, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=3, weights=distance .................\n",
      "[CV]  algorithm=auto, n_neighbors=3, weights=distance, score=0.6136363636363636, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=3, weights=distance .................\n",
      "[CV]  algorithm=auto, n_neighbors=3, weights=distance, score=0.6666666666666666, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=3, weights=distance .................\n",
      "[CV]  algorithm=auto, n_neighbors=3, weights=distance, score=0.7045454545454546, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=3, weights=distance .................\n",
      "[CV]  algorithm=auto, n_neighbors=3, weights=distance, score=0.7196969696969697, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=5, weights=uniform ..................\n",
      "[CV]  algorithm=auto, n_neighbors=5, weights=uniform, score=0.6590909090909091, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=5, weights=uniform ..................\n",
      "[CV]  algorithm=auto, n_neighbors=5, weights=uniform, score=0.7045454545454546, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=5, weights=uniform ..................\n",
      "[CV]  algorithm=auto, n_neighbors=5, weights=uniform, score=0.7348484848484849, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=5, weights=uniform ..................\n",
      "[CV]  algorithm=auto, n_neighbors=5, weights=uniform, score=0.6742424242424242, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=5, weights=distance .................\n",
      "[CV]  algorithm=auto, n_neighbors=5, weights=distance, score=0.6363636363636364, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=5, weights=distance .................\n",
      "[CV]  algorithm=auto, n_neighbors=5, weights=distance, score=0.696969696969697, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=5, weights=distance .................\n",
      "[CV]  algorithm=auto, n_neighbors=5, weights=distance, score=0.7196969696969697, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=5, weights=distance .................\n",
      "[CV]  algorithm=auto, n_neighbors=5, weights=distance, score=0.696969696969697, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=7, weights=uniform ..................\n",
      "[CV]  algorithm=auto, n_neighbors=7, weights=uniform, score=0.7121212121212122, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=7, weights=uniform ..................\n",
      "[CV]  algorithm=auto, n_neighbors=7, weights=uniform, score=0.6666666666666666, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=7, weights=uniform ..................\n",
      "[CV]  algorithm=auto, n_neighbors=7, weights=uniform, score=0.75, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=7, weights=uniform ..................\n",
      "[CV]  algorithm=auto, n_neighbors=7, weights=uniform, score=0.7272727272727273, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=7, weights=distance .................\n",
      "[CV]  algorithm=auto, n_neighbors=7, weights=distance, score=0.6893939393939394, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=7, weights=distance .................\n",
      "[CV]  algorithm=auto, n_neighbors=7, weights=distance, score=0.6666666666666666, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=7, weights=distance .................\n",
      "[CV]  algorithm=auto, n_neighbors=7, weights=distance, score=0.7196969696969697, total=   0.0s\n",
      "[CV] algorithm=auto, n_neighbors=7, weights=distance .................\n",
      "[CV]  algorithm=auto, n_neighbors=7, weights=distance, score=0.7348484848484849, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=3, weights=uniform .............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=3, weights=uniform, score=0.6287878787878788, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=3, weights=uniform .............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=3, weights=uniform, score=0.6666666666666666, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=3, weights=uniform .............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=3, weights=uniform, score=0.7045454545454546, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=3, weights=uniform .............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=3, weights=uniform, score=0.7196969696969697, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=3, weights=distance ............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=3, weights=distance, score=0.6212121212121212, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=3, weights=distance ............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=3, weights=distance, score=0.6666666666666666, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=3, weights=distance ............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=3, weights=distance, score=0.7045454545454546, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=3, weights=distance ............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=3, weights=distance, score=0.7196969696969697, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=5, weights=uniform .............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=5, weights=uniform, score=0.6515151515151515, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=5, weights=uniform .............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=5, weights=uniform, score=0.7121212121212122, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=5, weights=uniform .............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=5, weights=uniform, score=0.7196969696969697, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=5, weights=uniform .............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=5, weights=uniform, score=0.6742424242424242, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=5, weights=distance ............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=5, weights=distance, score=0.6363636363636364, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=5, weights=distance ............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=5, weights=distance, score=0.696969696969697, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=5, weights=distance ............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=5, weights=distance, score=0.7196969696969697, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=5, weights=distance ............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=5, weights=distance, score=0.696969696969697, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=7, weights=uniform .............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=7, weights=uniform, score=0.7121212121212122, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=7, weights=uniform .............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=7, weights=uniform, score=0.6590909090909091, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=7, weights=uniform .............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=7, weights=uniform, score=0.7121212121212122, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=7, weights=uniform .............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=7, weights=uniform, score=0.7272727272727273, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=7, weights=distance ............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=7, weights=distance, score=0.6893939393939394, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=7, weights=distance ............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=7, weights=distance, score=0.6590909090909091, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=7, weights=distance ............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=7, weights=distance, score=0.7196969696969697, total=   0.0s\n",
      "[CV] algorithm=ball_tree, n_neighbors=7, weights=distance ............\n",
      "[CV]  algorithm=ball_tree, n_neighbors=7, weights=distance, score=0.7348484848484849, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=3, weights=uniform ...............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=3, weights=uniform, score=0.6136363636363636, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=3, weights=uniform ...............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=3, weights=uniform, score=0.6515151515151515, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=3, weights=uniform ...............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=3, weights=uniform, score=0.7045454545454546, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=3, weights=uniform ...............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=3, weights=uniform, score=0.7121212121212122, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=3, weights=distance ..............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=3, weights=distance, score=0.6136363636363636, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=3, weights=distance ..............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=3, weights=distance, score=0.6666666666666666, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=3, weights=distance ..............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=3, weights=distance, score=0.7045454545454546, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=3, weights=distance ..............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  algorithm=kd_tree, n_neighbors=3, weights=distance, score=0.7196969696969697, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=5, weights=uniform ...............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=5, weights=uniform, score=0.6590909090909091, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=5, weights=uniform ...............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=5, weights=uniform, score=0.7045454545454546, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=5, weights=uniform ...............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=5, weights=uniform, score=0.7348484848484849, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=5, weights=uniform ...............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=5, weights=uniform, score=0.6742424242424242, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=5, weights=distance ..............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=5, weights=distance, score=0.6363636363636364, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=5, weights=distance ..............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=5, weights=distance, score=0.696969696969697, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=5, weights=distance ..............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=5, weights=distance, score=0.7196969696969697, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=5, weights=distance ..............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=5, weights=distance, score=0.696969696969697, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=7, weights=uniform ...............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=7, weights=uniform, score=0.7121212121212122, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=7, weights=uniform ...............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=7, weights=uniform, score=0.6666666666666666, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=7, weights=uniform ...............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=7, weights=uniform, score=0.75, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=7, weights=uniform ...............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=7, weights=uniform, score=0.7272727272727273, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=7, weights=distance ..............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=7, weights=distance, score=0.6893939393939394, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=7, weights=distance ..............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=7, weights=distance, score=0.6666666666666666, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=7, weights=distance ..............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=7, weights=distance, score=0.7196969696969697, total=   0.0s\n",
      "[CV] algorithm=kd_tree, n_neighbors=7, weights=distance ..............\n",
      "[CV]  algorithm=kd_tree, n_neighbors=7, weights=distance, score=0.7348484848484849, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=3, weights=uniform .................\n",
      "[CV]  algorithm=brute, n_neighbors=3, weights=uniform, score=0.6363636363636364, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=3, weights=uniform .................\n",
      "[CV]  algorithm=brute, n_neighbors=3, weights=uniform, score=0.6439393939393939, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=3, weights=uniform .................\n",
      "[CV]  algorithm=brute, n_neighbors=3, weights=uniform, score=0.7196969696969697, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=3, weights=uniform .................\n",
      "[CV]  algorithm=brute, n_neighbors=3, weights=uniform, score=0.7121212121212122, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=3, weights=distance ................\n",
      "[CV]  algorithm=brute, n_neighbors=3, weights=distance, score=0.6212121212121212, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=3, weights=distance ................\n",
      "[CV]  algorithm=brute, n_neighbors=3, weights=distance, score=0.6590909090909091, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=3, weights=distance ................\n",
      "[CV]  algorithm=brute, n_neighbors=3, weights=distance, score=0.7196969696969697, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=3, weights=distance ................\n",
      "[CV]  algorithm=brute, n_neighbors=3, weights=distance, score=0.7196969696969697, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=5, weights=uniform .................\n",
      "[CV]  algorithm=brute, n_neighbors=5, weights=uniform, score=0.6666666666666666, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=5, weights=uniform .................\n",
      "[CV]  algorithm=brute, n_neighbors=5, weights=uniform, score=0.6439393939393939, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=5, weights=uniform .................\n",
      "[CV]  algorithm=brute, n_neighbors=5, weights=uniform, score=0.7424242424242424, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=5, weights=uniform .................\n",
      "[CV]  algorithm=brute, n_neighbors=5, weights=uniform, score=0.6515151515151515, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=5, weights=distance ................\n",
      "[CV]  algorithm=brute, n_neighbors=5, weights=distance, score=0.6893939393939394, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=5, weights=distance ................\n",
      "[CV]  algorithm=brute, n_neighbors=5, weights=distance, score=0.6439393939393939, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=5, weights=distance ................\n",
      "[CV]  algorithm=brute, n_neighbors=5, weights=distance, score=0.7045454545454546, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=5, weights=distance ................\n",
      "[CV]  algorithm=brute, n_neighbors=5, weights=distance, score=0.6590909090909091, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=7, weights=uniform .................\n",
      "[CV]  algorithm=brute, n_neighbors=7, weights=uniform, score=0.7045454545454546, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=7, weights=uniform .................\n",
      "[CV]  algorithm=brute, n_neighbors=7, weights=uniform, score=0.6666666666666666, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=7, weights=uniform .................\n",
      "[CV]  algorithm=brute, n_neighbors=7, weights=uniform, score=0.6666666666666666, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=7, weights=uniform .................\n",
      "[CV]  algorithm=brute, n_neighbors=7, weights=uniform, score=0.6515151515151515, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=7, weights=distance ................\n",
      "[CV]  algorithm=brute, n_neighbors=7, weights=distance, score=0.696969696969697, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=7, weights=distance ................\n",
      "[CV]  algorithm=brute, n_neighbors=7, weights=distance, score=0.6742424242424242, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=7, weights=distance ................\n",
      "[CV]  algorithm=brute, n_neighbors=7, weights=distance, score=0.6742424242424242, total=   0.0s\n",
      "[CV] algorithm=brute, n_neighbors=7, weights=distance ................\n",
      "[CV]  algorithm=brute, n_neighbors=7, weights=distance, score=0.6590909090909091, total=   0.0s\n",
      "Fitting 4 folds for each of 45 candidates, totalling 180 fits\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  96 out of  96 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6515151515151515, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7045454545454546, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6515151515151515, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7045454545454546, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6439393939393939, total=   0.4s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.75, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6363636363636364, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.696969696969697, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6363636363636364, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.696969696969697, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6439393939393939, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7424242424242424, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.5s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6363636363636364, total=   0.4s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.696969696969697, total=   0.4s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7196969696969697, total=   0.4s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6439393939393939, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.696969696969697, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.4s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.5s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6439393939393939, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7424242424242424, total=   0.4s\n",
      "[CV] colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.0, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7424242424242424, total=   0.1s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6439393939393939, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7045454545454546, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6515151515151515, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7045454545454546, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6666666666666666, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.75, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.4s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6439393939393939, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.696969696969697, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.4s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6363636363636364, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.696969696969697, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6439393939393939, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7424242424242424, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6363636363636364, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.696969696969697, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6363636363636364, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7045454545454546, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6439393939393939, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7424242424242424, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7424242424242424, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6439393939393939, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.696969696969697, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6439393939393939, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.696969696969697, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6439393939393939, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.75, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7196969696969697, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6363636363636364, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.696969696969697, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6515151515151515, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7045454545454546, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6363636363636364, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7424242424242424, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6439393939393939, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.696969696969697, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.4s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6515151515151515, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7045454545454546, total=   0.5s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6363636363636364, total=   0.4s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7424242424242424, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7424242424242424, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6363636363636364, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7045454545454546, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7424242424242424, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6439393939393939, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7045454545454546, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6363636363636364, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.75, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6439393939393939, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7045454545454546, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6439393939393939, total=   0.4s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7045454545454546, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.4s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6363636363636364, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.75, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7196969696969697, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6515151515151515, total=   0.4s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.696969696969697, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6439393939393939, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7121212121212122, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6363636363636364, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.75, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7196969696969697, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7424242424242424, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6363636363636364, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.696969696969697, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7424242424242424, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6439393939393939, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7045454545454546, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.75, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6363636363636364, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.75, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7196969696969697, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6212121212121212, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.696969696969697, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.4s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7424242424242424, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6212121212121212, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7121212121212122, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.75, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6363636363636364, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.75, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7196969696969697, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7348484848484849, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6287878787878788, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.696969696969697, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7424242424242424, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6212121212121212, total=   0.4s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7045454545454546, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7272727272727273, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.75, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.6363636363636364, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.75, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=1000, n_jobs=4, subsample=0.7, score=0.7196969696969697, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# model_gridSearch Function으로 최적 하이퍼 파라미터가 적용된 모델 가져오기\n",
    "voting = model_gridSearch(models, params, X_train_onehot, X_test_onehot, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8193832599118943\n",
      "0.7807823129251701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       147\n",
      "           1       0.80      0.65      0.72        80\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       227\n",
      "   macro avg       0.81      0.78      0.79       227\n",
      "weighted avg       0.82      0.82      0.81       227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# voting 모델에 적용 및 학습, 예측\n",
    "voting = [('Logistic', voting[0]),('Decision',voting[1]),\n",
    "          ('KNeighbors',voting[2]),('XGBoost',voting[3])]\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "                    estimators = voting,\n",
    "                    voting = 'soft'\n",
    "            )\n",
    "\n",
    "voting_clf.fit(X_train_onehot, y_train)\n",
    "voting_pred = voting_clf.predict(X_test_onehot)\n",
    "\n",
    "print(accuracy_score(y_test, voting_pred))\n",
    "print(roc_auc_score(y_test, voting_pred))\n",
    "print(classification_report(y_test, voting_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Titanic with XGBoost.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
